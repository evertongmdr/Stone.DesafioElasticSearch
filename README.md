# Desafio ElasticSearch Stone


## Tier 0

### Diagrama Arquitetura

![Descri√ß√£o da imagem](https://github.com/evertongmdr/Stone.DesafioElasticSearch/blob/master/documentos/diagrama-arquitetura.png)

### Defini√ß√µes Tiers

#### Tier 1: Gerador de Massa de Dados - Console App (Kafka Producer)

Este aplicativo de console √© um producer Kafka que gera e envia grandes volumes de dados de transa√ß√µes para um cluster Kafka. Ele √© ideal para testes de performance, escalabilidade e cen√°rios de estresse, simulando diferentes n√≠veis de carga no sistema.

##### Como Funciona

Ao executar o aplicativo, voc√™ ver√° um menu interativo que permite escolher entre diferentes cen√°rios de gera√ß√£o de dados. Cada cen√°rio envia um n√∫mero espec√≠fico de mensagens por transa√ß√£o, simulando diferentes n√≠veis de carga no sistema.


Descri√ß√£o dos Cen√°rios

##### Menu Principal

##### Descri√ß√£o dos Cen√°rios

| Op√ß√£o | Cen√°rio       | Batch Size | M√°x. Batches/Envio | Delay (ms) | Total de Mensagens |
|-------|---------------|-----------|------------------|------------|------------------|
| 1     | Alta Carga    | 4.000     | 100              | 500        | 400.000          |
| 2     | M√©dia Carga   | 1.000     | 50               | 250        | 50.000           |
| 3     | Baixa Carga   | 100       | 10               | 200        | 1.000            |

###### Explica√ß√£o dos par√¢metros

- **Batch Size:** Quantidade de mensagens geradas por lote.
- **M√°x. Batches/Envio:** Quantos lotes s√£o enviados em sequ√™ncia antes de aguardar o delay.
- **Delay (ms):** Pausa entre envios de lotes, em milissegundos.

##### Detalhes Producer
- O producer Kafka √© configurado com EnableIdempotence = true e Acks = All para garantir envio confi√°vel.
- Cada batch √© enviado em paralelo usando Parallel.ForEachAsync.
- As transa√ß√µes Kafka s√£o iniciadas com BeginTransaction() e confirmadas com CommitTransaction().
- Em caso de erro, a transa√ß√£o √© abortada com AbortTransaction() e registrada no log.
- Cada mensagem possui headers com informa√ß√µes de aplica√ß√£o e correlationId.

### Tier 2: Consumer de Transa√ß√µes - Console App (Kafka Consumer)

Este aplicativo de console √© um consumer Kafka que consome mensagens de transa√ß√µes geradas pelo Producer, processa os dados em paralelo e persiste no Elasticsearch. Ele √© ideal para cen√°rios de ingest√£o em larga escala e processamento confi√°vel de mensagens.

##### Como Funciona

O app se conecta a um t√≥pico Kafka, consome batches de mensagens e processa cada batch em paralelo usando **Channels** e **Tasks**. Ele garante:

- **Processamento em paralelo** com n√∫mero configur√°vel de canais (`NumberChannels`)
- **Retry de opera√ß√µes cr√≠ticas** usando Polly para Kafka e Elasticsearch
- **Persist√™ncia confi√°vel** no Elasticsearch
- **Commit controlado** das mensagens Kafka
- **Dead Letter Queue (DLQ)** para mensagens que falham

##### Escalabilidade Horizontal do Consumer

O Consumer Kafka foi projetado para rodar m√∫ltiplas inst√¢ncias em paralelo, aproveitando o agrupamento de consumidores (GroupId) do Kafka. Isso significa que v√°rias inst√¢ncias podem processar mensagens do mesmo t√≥pico, dividindo as parti√ß√µes entre si.

No caso:

- Cada consumidor √© registrado como um **HostedService** e pertence ao mesmo **GroupId Kafka**.
-  O Kafka realiza load balancing autom√°tico:
      - Cada parti√ß√£o do t√≥pico √© atribu√≠da a apenas um consumidor dentro do grupo.
      - Se houver mais consumidores que parti√ß√µes, alguns consumidores ficar√£o ociosos.
      - Se houver menos consumidores que parti√ß√µes, alguns consumidores processar√£o m√∫ltiplas parti√ß√µes.
 
Poder analisar melhor atrav√©s do [diagrama da arquitetura](#diagrama-arquitetura).

   
##### Detalhes Consumer

1. **Inicializa√ß√£o do Consumer**
   - O app cria um Consumer Kafka com configura√ß√µes de **Idempot√™ncia** e **Read Committed**.
   - O Consumer se inscreve no t√≥pico configurado (`TransactionConsumer`).

2. **Leitura de mensagens do Kafka**
   - As mensagens chegam em **batches JSON** contendo listas de `Transaction`.
   - Cada batch √© escrito em um **Channel** para processamento paralelo.

3. **Processamento paralelo dos batches**
   - Cada canal √© processado por uma **Task separada** (`ProcessAndPersistBatchesToElasticAsync`).
   - Cada batch √© persistido no **Elasticsearch** em bulk (`bulkSize = 5000`).
   - Se o Elasticsearch falhar, **Polly faz retry autom√°tico**.

4. **Commit das mensagens Kafka**
   - Somente ap√≥s sucesso no Elasticsearch o Consumer **confirma o offset**.
   - Se o processamento falhar de forma cr√≠tica, as mensagens v√£o para a **Dead Letter Queue (DLQ)**.

5. **Notifica√ß√£o de erros cr√≠ticos**
   - Erros graves s√£o registrados no log e podem disparar alertas (Teams, Slack, SNS, etc.) via m√©todo `NotifyTeam`.

6. **Encerramento do Consumer**
   - Quando o app √© interrompido, o Channel √© fechado e todas as Tasks aguardam finalizar.
   - O Consumer fecha a conex√£o com Kafka de forma segura.
  
## Configura√ß√µes Importantes

| Configura√ß√£o                       | Descri√ß√£o                                                                                 |
|-----------------------------------|-------------------------------------------------------------------------------------------|
| `NumberChannels`                   | N√∫mero de canais paralelos para processamento dos batches. Ajust√°vel conforme recursos do host. |
| `ClientId / GroupId`               | Identifica√ß√£o do consumidor no cluster Kafka.                                             |
| `EnableAutoCommit / EnableAutoOffsetStore` | O offset √© controlado manualmente ap√≥s persist√™ncia no Elasticsearch.               |
| `IsolationLevel`                   | Garante leitura apenas de transa√ß√µes commitadas.                                         |


### Tier 3: API de Leitura (Transaction API)

##### Vis√£o Geral
A API √© respons√°vel por fornecer acesso √†s transa√ß√µes persistidas no Elasticsearch.
Ela utiliza o √≠ndice de leitura (transactions-read) para consultas e agrega√ß√µes, garantindo que a leitura n√£o impacte a escrita.


##### Pol√≠tica de Reten√ß√£o (ILM)

A API consulta dados em √≠ndices gerenciados por uma pol√≠tica ILM (transactions_index_policy), que segue as recomenda√ß√µes:
- 85% das consultas s√£o atendidas nos √∫ltimos 7 dias (fase Hot).
- 99% das consultas s√£o atendidas nos √∫ltimos 30 dias (fases Hot + Warm + Cold).
- Os dados s√£o mantidos por 12 meses, atendendo ao requisito de reten√ß√£o.


##### Endpoints Dispon√≠veis

| M√©todo | Endpoint                       | Descri√ß√£o                                                                 |
|--------|--------------------------------|---------------------------------------------------------------------------|
| GET    | `/transactions`                | Retorna transa√ß√µes paginadas por **clientId** e intervalo de datas         |
| GET    | `/transactions/GetDailyTotals` | Retorna totais di√°rios das transa√ß√µes, agrupados por tipo de transa√ß√£o     |

## Estrat√©gia de Indexa√ß√£o e Persist√™ncia no ElasticSerach

A pol√≠tica ILM `transactions_index_policy` organiza os dados conforme a frequ√™ncia de acesso e a reten√ß√£o:

| Cen√°rio | Percentual de Consultas | Fase ILM | Estrat√©gia |
|---------|------------------------|----------|------------|
| **C1 ‚Äì Mais acessados** | 85% | Hot (0 a 7 dias) | √çndices ativos para escrita e leitura. Rollover di√°rio ou ao atingir 50GB. |
| **C2 ‚Äì Menos acessados** | 99% at√© 30 dias | Warm (7 a 30 dias) | Redu√ß√£o de shards, forcemerge para compactar em 1 segmento. Alocados em n√≥s warm. |
| **C3 ‚Äì Raramente acessados** | Consultas acima de 30 dias | Cold (>30 dias) | √çndices congelados (`freeze`). Alocados em n√≥s cold para reduzir custo. |
| **C4 ‚Äì Dados expirados** | Reten√ß√£o >12 meses | Delete (>12 meses) | √çndices exclu√≠dos automaticamente. |

üí° Observa√ß√µes:
- Percentuais de consultas ajudam a decidir em qual fase os dados permanecem.  
- A pol√≠tica garante **otimiza√ß√£o de escrita/leitura**, **economia de recursos** e **reten√ß√£o de 12 meses**.


## Tecnologias Usadas
- **.NET** 
- **Kafka**
- **ElasticSearch**
- **Docker**
